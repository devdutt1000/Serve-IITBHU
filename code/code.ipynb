{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e1253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:49:41.248329Z",
     "iopub.status.busy": "2025-12-16T17:49:41.247896Z",
     "iopub.status.idle": "2025-12-16T17:49:45.813564Z",
     "shell.execute_reply": "2025-12-16T17:49:45.812494Z"
    },
    "papermill": {
     "duration": 4.572064,
     "end_time": "2025-12-16T17:49:45.814706",
     "exception": true,
     "start_time": "2025-12-16T17:49:41.242642",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FIXING NUMPY COMPATIBILITY\n",
      "============================================================\n",
      "Downgrading NumPy to version 1.x for compatibility...\n",
      "‚úì NumPy downgraded successfully\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20/1663642288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIXING NUMPY COMPATIBILITY ISSUE FIRST\n",
    "# ============================================================================\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIXING NUMPY COMPATIBILITY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Downgrading NumPy to version 1.x for compatibility...\")\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2\"])\n",
    "    print(\"‚úì NumPy downgraded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Warning: {e}\")\n",
    "    print(\"Continuing anyway...\")\n",
    "\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths (adjusted for correct dataset location)\n",
    "DATASET_PATH = '/kaggle/input/military-object-dataset/military_object_dataset'\n",
    "OUTPUT_PATH = '/kaggle/working'\n",
    "WEIGHTS_PATH = f'{OUTPUT_PATH}/weights'\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(WEIGHTS_PATH, exist_ok=True)\n",
    "\n",
    "# Training Configuration\n",
    "CONFIG = {\n",
    "    'model': 'yolov8m.pt',  # Medium model - good balance\n",
    "    # Use 'yolov8n.pt' for faster training (30 min less)\n",
    "    # Use 'yolov8l.pt' for better accuracy (if you have time)\n",
    "    \n",
    "    'epochs': 60,  # With early stopping, will stop around 50-70\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,  # Adjust based on GPU memory\n",
    "    'patience': 15,  # Early stopping patience\n",
    "    'device': '0,1',  # Use both T4 GPUs\n",
    "    'workers': 8,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'cos_lr': True,\n",
    "    'close_mosaic': 10,  # Disable mosaic in last 10 epochs\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SYSTEM CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE CORRECTED YAML\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING DATASET CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read original YAML to get class names\n",
    "original_yaml_path = f'{DATASET_PATH}/military_dataset.yaml'\n",
    "try:\n",
    "    with open(original_yaml_path, 'r') as f:\n",
    "        original_yaml = yaml.safe_load(f)\n",
    "        class_names = original_yaml.get('names', [f'class_{i}' for i in range(12)])\n",
    "        num_classes = original_yaml.get('nc', 12)\n",
    "        print(f\"‚úì Found {num_classes} classes from original YAML\")\n",
    "        print(f\"‚úì Classes: {class_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Warning reading original YAML: {e}\")\n",
    "    print(\"‚ö† Using default class names\")\n",
    "    num_classes = 12\n",
    "    class_names = [f'class_{i}' for i in range(num_classes)]\n",
    "\n",
    "# Verify dataset structure\n",
    "print(\"\\nVerifying dataset structure...\")\n",
    "required_dirs = {\n",
    "    'train/images': 0,\n",
    "    'train/labels': 0,\n",
    "    'val/images': 0,\n",
    "    'val/labels': 0,\n",
    "    'test/images': 0\n",
    "}\n",
    "\n",
    "for dir_name in required_dirs.keys():\n",
    "    dir_path = Path(DATASET_PATH) / dir_name\n",
    "    if dir_path.exists():\n",
    "        count = len(list(dir_path.glob('*')))\n",
    "        required_dirs[dir_name] = count\n",
    "        print(f\"‚úì {dir_name}: {count} files\")\n",
    "    else:\n",
    "        print(f\"‚úó {dir_name}: NOT FOUND\")\n",
    "\n",
    "# Create corrected YAML with proper absolute paths\n",
    "data_yaml = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "data_yaml_path = f'{OUTPUT_PATH}/corrected_data.yaml'\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "    \n",
    "print(f\"\\n‚úì Created corrected YAML at: {data_yaml_path}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# DATA AUGMENTATION SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "# Strong augmentation for robustness\n",
    "augmentation = {\n",
    "    'hsv_h': 0.015,  # HSV-Hue augmentation\n",
    "    'hsv_s': 0.7,    # HSV-Saturation augmentation\n",
    "    'hsv_v': 0.4,    # HSV-Value augmentation\n",
    "    'degrees': 10.0,  # Rotation (+/- deg)\n",
    "    'translate': 0.1, # Translation (+/- fraction)\n",
    "    'scale': 0.5,     # Scale (+/- gain)\n",
    "    'shear': 0.0,     # Shear (+/- deg)\n",
    "    'perspective': 0.0,  # Perspective (+/- fraction)\n",
    "    'flipud': 0.0,    # Flip up-down probability\n",
    "    'fliplr': 0.5,    # Flip left-right probability\n",
    "    'mosaic': 1.0,    # Mosaic augmentation probability\n",
    "    'mixup': 0.1,     # Mixup augmentation probability\n",
    "    'copy_paste': 0.1 # Copy-paste augmentation probability\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INITIALIZING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load pretrained YOLO model\n",
    "model = YOLO(CONFIG['model'])\n",
    "print(f\"‚úì Loaded model: {CONFIG['model']}\")\n",
    "print(f\"‚úì Using GPUs: {CONFIG['device']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK FOR EXISTING TRAINING (AUTO-RESUME)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHECKING FOR EXISTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "last_checkpoint = f'{OUTPUT_PATH}/train/weights/last.pt'\n",
    "resume_training = False\n",
    "\n",
    "if Path(last_checkpoint).exists():\n",
    "    print(f\"‚úì Found existing checkpoint: {last_checkpoint}\")\n",
    "    \n",
    "    try:\n",
    "        # Load checkpoint to check epoch\n",
    "        checkpoint = torch.load(last_checkpoint, map_location='cpu')\n",
    "        last_epoch = checkpoint.get('epoch', -1)\n",
    "        print(f\"‚úì Last completed epoch: {last_epoch}\")\n",
    "        print(f\"‚úì Will resume from epoch {last_epoch + 1}\")\n",
    "        \n",
    "        resume_training = True\n",
    "        model = YOLO(last_checkpoint)  # Load from checkpoint\n",
    "        print(\"‚úì Loaded model from checkpoint\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Could not load checkpoint: {e}\")\n",
    "        print(\"‚ö† Starting fresh training...\")\n",
    "        resume_training = False\n",
    "else:\n",
    "    print(\"‚úó No existing checkpoint found\")\n",
    "    print(\"‚úì Starting fresh training...\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# START TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "if resume_training:\n",
    "    print(f\"üîÑ RESUMING from checkpoint\")\n",
    "else:\n",
    "    print(f\"üÜï STARTING fresh training\")\n",
    "print(f\"Estimated time: 2-3 hours\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "print(f\"Using corrected YAML: {data_yaml_path}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    imgsz=CONFIG['imgsz'],\n",
    "    batch=CONFIG['batch'],\n",
    "    patience=CONFIG['patience'],\n",
    "    device=CONFIG['device'],\n",
    "    workers=CONFIG['workers'],\n",
    "    optimizer=CONFIG['optimizer'],\n",
    "    lr0=CONFIG['lr0'],\n",
    "    lrf=CONFIG['lrf'],\n",
    "    cos_lr=CONFIG['cos_lr'],\n",
    "    close_mosaic=CONFIG['close_mosaic'],\n",
    "    project=OUTPUT_PATH,\n",
    "    name='train',\n",
    "    exist_ok=True,\n",
    "    pretrained=True if not resume_training else False,\n",
    "    resume=resume_training,  # Enable resume mode\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=False,\n",
    "    save=True,\n",
    "    save_period=5,  # Save checkpoint every 10 epochs\n",
    "    **augmentation\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUNNING VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Validate the best model\n",
    "best_model_path = f'{OUTPUT_PATH}/train/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "val_results = model.val(\n",
    "    data=data_yaml_path,\n",
    "    imgsz=CONFIG['imgsz'],\n",
    "    batch=CONFIG['batch'],\n",
    "    device=CONFIG['device'],\n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    project=OUTPUT_PATH,\n",
    "    name='validation'\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# PRINT RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best model saved at: {best_model_path}\")\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  mAP@50: {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"  Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"  Recall: {val_results.box.mr:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save results summary\n",
    "results_summary = {\n",
    "    'model': CONFIG['model'],\n",
    "    'epochs_trained': len(results.box.map) if hasattr(results.box, 'map') else CONFIG['epochs'],\n",
    "    'mAP@50': float(val_results.box.map50),\n",
    "    'mAP@50-95': float(val_results.box.map),\n",
    "    'precision': float(val_results.box.mp),\n",
    "    'recall': float(val_results.box.mr),\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'{OUTPUT_PATH}/training_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Training summary saved!\")\n",
    "print(\"\\nNext step: Run inference script to generate predictions\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - Best weights: {best_model_path}\")\n",
    "print(f\"  - Last weights: {OUTPUT_PATH}/train/weights/last.pt\")\n",
    "print(f\"  - Training plots: {OUTPUT_PATH}/train/\")\n",
    "print(f\"  - Validation results: {OUTPUT_PATH}/validation/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7502af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d12758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:25:45.876505Z",
     "iopub.status.busy": "2025-12-16T17:25:45.876211Z",
     "iopub.status.idle": "2025-12-16T17:27:22.082974Z",
     "shell.execute_reply": "2025-12-16T17:27:22.082273Z",
     "shell.execute_reply.started": "2025-12-16T17:25:45.876486Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths (adjust these based on your setup)\n",
    "DATASET_PATH = '/kaggle/input/military-object-dataset/military_object_dataset'\n",
    "MODEL_PATH = '/kaggle/working/train/weights/best.pt'  # Path to trained model\n",
    "OUTPUT_PATH = '/kaggle/working/validation_results'\n",
    "DATA_YAML_PATH = '/kaggle/working/corrected_data.yaml'\n",
    "\n",
    "# Validation Configuration\n",
    "CONFIG = {\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'device': '0',  # Single GPU for validation\n",
    "    'workers': 8,\n",
    "    'conf_thres': 0.001,  # Low threshold for comprehensive evaluation\n",
    "    'iou_thres': 0.6,\n",
    "    'max_det': 300,\n",
    "    'save_json': True,\n",
    "    'save_txt': True,\n",
    "    'plots': True,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# SYSTEM CHECK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION SYSTEM CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY FILES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFYING FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if model exists\n",
    "if not Path(MODEL_PATH).exists():\n",
    "    print(f\"‚úó ERROR: Model not found at {MODEL_PATH}\")\n",
    "    print(\"\\nAvailable models:\")\n",
    "    weights_dir = Path(MODEL_PATH).parent\n",
    "    if weights_dir.exists():\n",
    "        for f in weights_dir.glob('*.pt'):\n",
    "            print(f\"  - {f}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(f\"‚úì Model found: {MODEL_PATH}\")\n",
    "    model_size = Path(MODEL_PATH).stat().st_size / 1e6\n",
    "    print(f\"  Size: {model_size:.2f} MB\")\n",
    "\n",
    "# Check if data YAML exists\n",
    "if not Path(DATA_YAML_PATH).exists():\n",
    "    print(f\"‚úó ERROR: Data YAML not found at {DATA_YAML_PATH}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(f\"‚úì Data YAML found: {DATA_YAML_PATH}\")\n",
    "\n",
    "# Load and verify YAML content\n",
    "with open(DATA_YAML_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    print(f\"  Classes: {data_config['nc']}\")\n",
    "    # Handle both list and dict formats for class names\n",
    "    if isinstance(data_config['names'], dict):\n",
    "        class_names_preview = list(data_config['names'].values())[:3]\n",
    "    else:\n",
    "        class_names_preview = data_config['names'][:3]\n",
    "    print(f\"  Class names: {class_names_preview}... (showing first 3)\")\n",
    "\n",
    "# Verify validation data exists\n",
    "val_images_path = Path(data_config['path']) / data_config['val']\n",
    "if val_images_path.exists():\n",
    "    val_count = len(list(val_images_path.glob('*')))\n",
    "    print(f\"‚úì Validation images: {val_count} files\")\n",
    "else:\n",
    "    print(f\"‚úó ERROR: Validation images not found at {val_images_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOADING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(f\"‚úì Model loaded successfully\")\n",
    "    \n",
    "    # Get model info\n",
    "    model_info = model.info(verbose=False)\n",
    "    print(f\"‚úì Model type: {model.model.__class__.__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó ERROR loading model: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUNNING VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Validation set: {val_images_path}\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "print(f\"Batch size: {CONFIG['batch']}\")\n",
    "print(f\"Image size: {CONFIG['imgsz']}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Run validation\n",
    "val_results = model.val(\n",
    "    data=DATA_YAML_PATH,\n",
    "    imgsz=CONFIG['imgsz'],\n",
    "    batch=CONFIG['batch'],\n",
    "    device=CONFIG['device'],\n",
    "    workers=CONFIG['workers'],\n",
    "    conf=CONFIG['conf_thres'],\n",
    "    iou=CONFIG['iou_thres'],\n",
    "    max_det=CONFIG['max_det'],\n",
    "    save_json=CONFIG['save_json'],\n",
    "    save_txt=CONFIG['save_txt'],\n",
    "    plots=CONFIG['plots'],\n",
    "    verbose=CONFIG['verbose'],\n",
    "    project=OUTPUT_PATH,\n",
    "    name='val',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# EXTRACT AND DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall metrics\n",
    "print(\"\\nüìä Overall Metrics:\")\n",
    "print(f\"  mAP@50:     {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95:  {val_results.box.map:.4f}\")\n",
    "print(f\"  Precision:  {val_results.box.mp:.4f}\")\n",
    "print(f\"  Recall:     {val_results.box.mr:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\nüìã Per-Class Metrics:\")\n",
    "print(f\"{'Class':<20} {'mAP@50':>10} {'mAP@50-95':>10} {'Precision':>10} {'Recall':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Handle both list and dict formats for class names\n",
    "if isinstance(data_config['names'], dict):\n",
    "    class_names = list(data_config['names'].values())\n",
    "else:\n",
    "    class_names = data_config['names']\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    if i < len(val_results.box.ap50):\n",
    "        map50 = val_results.box.ap50[i]\n",
    "        map50_95 = val_results.box.ap[i]\n",
    "        # Get per-class precision and recall if available\n",
    "        print(f\"{class_name:<20} {map50:>10.4f} {map50_95:>10.4f} {'-':>10} {'-':>10}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE DETAILED RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comprehensive results dictionary\n",
    "results_dict = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_path': MODEL_PATH,\n",
    "    'dataset_path': DATASET_PATH,\n",
    "    'configuration': CONFIG,\n",
    "    'overall_metrics': {\n",
    "        'mAP@50': float(val_results.box.map50),\n",
    "        'mAP@50-95': float(val_results.box.map),\n",
    "        'precision': float(val_results.box.mp),\n",
    "        'recall': float(val_results.box.mr),\n",
    "    },\n",
    "    'per_class_metrics': {}\n",
    "}\n",
    "\n",
    "# Add per-class metrics\n",
    "for i, class_name in enumerate(class_names):\n",
    "    if i < len(val_results.box.ap50):\n",
    "        results_dict['per_class_metrics'][class_name] = {\n",
    "            'mAP@50': float(val_results.box.ap50[i]) if val_results.box.ap50[i] == val_results.box.ap50[i] else 0.0,  # Check for NaN\n",
    "            'mAP@50-95': float(val_results.box.ap[i]) if val_results.box.ap[i] == val_results.box.ap[i] else 0.0\n",
    "        }\n",
    "\n",
    "# Save to JSON\n",
    "results_json_path = f'{OUTPUT_PATH}/validation_results.json'\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "print(f\"‚úì Detailed results saved: {results_json_path}\")\n",
    "\n",
    "# Save summary text file\n",
    "summary_path = f'{OUTPUT_PATH}/validation_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"VALIDATION SUMMARY\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Timestamp: {results_dict['timestamp']}\\n\")\n",
    "    f.write(f\"Model: {MODEL_PATH}\\n\\n\")\n",
    "    f.write(\"Overall Metrics:\\n\")\n",
    "    f.write(f\"  mAP@50:     {val_results.box.map50:.4f}\\n\")\n",
    "    f.write(f\"  mAP@50-95:  {val_results.box.map:.4f}\\n\")\n",
    "    f.write(f\"  Precision:  {val_results.box.mp:.4f}\\n\")\n",
    "    f.write(f\"  Recall:     {val_results.box.mr:.4f}\\n\\n\")\n",
    "    f.write(\"Per-Class Metrics:\\n\")\n",
    "    for class_name, metrics in results_dict['per_class_metrics'].items():\n",
    "        f.write(f\"  {class_name}:\\n\")\n",
    "        f.write(f\"    mAP@50: {metrics['mAP@50']:.4f}\\n\")\n",
    "        f.write(f\"    mAP@50-95: {metrics['mAP@50-95']:.4f}\\n\")\n",
    "print(f\"‚úì Summary saved: {summary_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# ADDITIONAL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADDITIONAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find best and worst performing classes\n",
    "per_class_map = results_dict['per_class_metrics']\n",
    "if per_class_map:\n",
    "    sorted_classes = sorted(per_class_map.items(), \n",
    "                           key=lambda x: x[1]['mAP@50'], \n",
    "                           reverse=True)\n",
    "    \n",
    "    print(\"\\nüèÜ Top 3 Performing Classes:\")\n",
    "    for i, (class_name, metrics) in enumerate(sorted_classes[:3], 1):\n",
    "        print(f\"  {i}. {class_name}: mAP@50 = {metrics['mAP@50']:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Bottom 3 Performing Classes:\")\n",
    "    for i, (class_name, metrics) in enumerate(sorted_classes[-3:], 1):\n",
    "        print(f\"  {i}. {class_name}: mAP@50 = {metrics['mAP@50']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Output Directory: {OUTPUT_PATH}\")\n",
    "print(f\"\\nGenerated Files:\")\n",
    "print(f\"  ‚úì validation_results.json - Detailed metrics\")\n",
    "print(f\"  ‚úì validation_summary.txt - Human-readable summary\")\n",
    "print(f\"  ‚úì Confusion matrix and plots (in val/ subdirectory)\")\n",
    "print(f\"\\nüéØ Overall Performance:\")\n",
    "print(f\"  mAP@50: {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95: {val_results.box.map:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Performance interpretation\n",
    "if val_results.box.map50 > 0.7:\n",
    "    print(\"\\n‚úÖ Excellent performance! Model is ready for deployment.\")\n",
    "elif val_results.box.map50 > 0.5:\n",
    "    print(\"\\n‚úì Good performance! Consider fine-tuning for better results.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Performance needs improvement. Consider:\")\n",
    "    print(\"  - Training for more epochs\")\n",
    "    print(\"  - Using a larger model\")\n",
    "    print(\"  - Adjusting hyperparameters\")\n",
    "    print(\"  - Collecting more training data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9447",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e809c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:32:09.554153Z",
     "iopub.status.busy": "2025-12-16T17:32:09.553802Z",
     "iopub.status.idle": "2025-12-16T17:33:20.967529Z",
     "shell.execute_reply": "2025-12-16T17:33:20.966903Z",
     "shell.execute_reply.started": "2025-12-16T17:32:09.554129Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = '/kaggle/input/military-object-dataset/military_object_dataset'\n",
    "MODEL_PATH = '/kaggle/working/train/weights/best.pt'  # Trained model\n",
    "OUTPUT_PATH = '/kaggle/working/inference_results'\n",
    "DATA_YAML_PATH = '/kaggle/working/corrected_data.yaml'\n",
    "TEST_IMAGES_PATH = f'{DATASET_PATH}/test/images'\n",
    "\n",
    "# Inference Configuration\n",
    "CONFIG = {\n",
    "    'imgsz': 640,\n",
    "    'conf_thres': 0.25,  # Confidence threshold\n",
    "    'iou_thres': 0.45,   # NMS IOU threshold\n",
    "    'max_det': 300,      # Maximum detections per image\n",
    "    'device': '0',       # GPU device\n",
    "    'agnostic_nms': False,\n",
    "    'save_txt': True,\n",
    "    'save_conf': True,\n",
    "    'save_crop': False,  # Set to True to save cropped detections\n",
    "    'visualize': True,   # Save visualization images\n",
    "    'line_width': 2,\n",
    "    'batch': 16\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(f'{OUTPUT_PATH}/labels', exist_ok=True)\n",
    "os.makedirs(f'{OUTPUT_PATH}/visualizations', exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# SYSTEM CHECK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INFERENCE SYSTEM CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY FILES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFYING FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check model\n",
    "if not Path(MODEL_PATH).exists():\n",
    "    print(f\"‚úó ERROR: Model not found at {MODEL_PATH}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(f\"‚úì Model found: {MODEL_PATH}\")\n",
    "    model_size = Path(MODEL_PATH).stat().st_size / 1e6\n",
    "    print(f\"  Size: {model_size:.2f} MB\")\n",
    "\n",
    "# Check data YAML\n",
    "if not Path(DATA_YAML_PATH).exists():\n",
    "    print(f\"‚úó ERROR: Data YAML not found at {DATA_YAML_PATH}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(f\"‚úì Data YAML found: {DATA_YAML_PATH}\")\n",
    "\n",
    "# Load YAML to get class names\n",
    "with open(DATA_YAML_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    # Handle both list and dict formats for class names\n",
    "    if isinstance(data_config['names'], dict):\n",
    "        class_names = list(data_config['names'].values())\n",
    "    else:\n",
    "        class_names = data_config['names']\n",
    "    num_classes = data_config['nc']\n",
    "    print(f\"  Classes: {num_classes}\")\n",
    "    print(f\"  Class names loaded: {len(class_names)} classes\")\n",
    "\n",
    "# Check test images\n",
    "test_path = Path(TEST_IMAGES_PATH)\n",
    "if not test_path.exists():\n",
    "    print(f\"‚úó ERROR: Test images not found at {test_path}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    test_images = list(test_path.glob('*.jpg')) + list(test_path.glob('*.png'))\n",
    "    print(f\"‚úì Test images found: {len(test_images)} files\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOADING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(f\"‚úì Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó ERROR loading model: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUNNING INFERENCE ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "print(f\"Confidence threshold: {CONFIG['conf_thres']}\")\n",
    "print(f\"IOU threshold: {CONFIG['iou_thres']}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(\n",
    "    source=TEST_IMAGES_PATH,\n",
    "    imgsz=CONFIG['imgsz'],\n",
    "    conf=CONFIG['conf_thres'],\n",
    "    iou=CONFIG['iou_thres'],\n",
    "    max_det=CONFIG['max_det'],\n",
    "    device=CONFIG['device'],\n",
    "    agnostic_nms=CONFIG['agnostic_nms'],\n",
    "    save_txt=CONFIG['save_txt'],\n",
    "    save_conf=CONFIG['save_conf'],\n",
    "    save_crop=CONFIG['save_crop'],\n",
    "    line_width=CONFIG['line_width'],\n",
    "    project=OUTPUT_PATH,\n",
    "    name='predictions',\n",
    "    exist_ok=True,\n",
    "    verbose=True,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Inference complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESS AND SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROCESSING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collect all predictions\n",
    "all_predictions = []\n",
    "detection_stats = {\n",
    "    'total_images': len(test_images),\n",
    "    'images_with_detections': 0,\n",
    "    'total_detections': 0,\n",
    "    'detections_per_class': {}\n",
    "}\n",
    "\n",
    "# Initialize detection counts for all classes\n",
    "for class_name in class_names:\n",
    "    detection_stats['detections_per_class'][class_name] = 0\n",
    "\n",
    "print(\"\\nProcessing predictions...\")\n",
    "for i, result in enumerate(tqdm(results)):\n",
    "    img_path = result.path\n",
    "    img_name = Path(img_path).stem\n",
    "    \n",
    "    # Get detections\n",
    "    boxes = result.boxes\n",
    "    \n",
    "    if len(boxes) > 0:\n",
    "        detection_stats['images_with_detections'] += 1\n",
    "        detection_stats['total_detections'] += len(boxes)\n",
    "        \n",
    "        # Process each detection\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            \n",
    "            # Safely get class name\n",
    "            if cls < len(class_names):\n",
    "                class_name = class_names[cls]\n",
    "            else:\n",
    "                class_name = f'class_{cls}'\n",
    "                if class_name not in detection_stats['detections_per_class']:\n",
    "                    detection_stats['detections_per_class'][class_name] = 0\n",
    "            \n",
    "            # Update class statistics\n",
    "            detection_stats['detections_per_class'][class_name] += 1\n",
    "            \n",
    "            # Store prediction\n",
    "            prediction = {\n",
    "                'image': img_name,\n",
    "                'class_id': cls,\n",
    "                'class_name': class_name,\n",
    "                'confidence': conf,\n",
    "                'bbox': [float(x1), float(y1), float(x2), float(y2)],\n",
    "                'width': float(x2 - x1),\n",
    "                'height': float(y2 - y1)\n",
    "            }\n",
    "            all_predictions.append(prediction)\n",
    "    \n",
    "    # Save visualization if enabled\n",
    "    if CONFIG['visualize'] and len(boxes) > 0:\n",
    "        # Read original image\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Draw detections\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            \n",
    "            # Safely get class name\n",
    "            if cls < len(class_names):\n",
    "                class_name = class_names[cls]\n",
    "            else:\n",
    "                class_name = f'class_{cls}'\n",
    "            \n",
    "            # Draw box\n",
    "            color = (0, 255, 0)  # Green\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw label\n",
    "            label = f\"{class_name} {conf:.2f}\"\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(img, (x1, y1 - h - 10), (x1 + w, y1), color, -1)\n",
    "            cv2.putText(img, label, (x1, y1 - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "        \n",
    "        # Save visualization\n",
    "        vis_path = f'{OUTPUT_PATH}/visualizations/{img_name}.jpg'\n",
    "        cv2.imwrite(vis_path, img)\n",
    "\n",
    "print(\"\\n‚úì Results processed!\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE PREDICTIONS IN MULTIPLE FORMATS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Save as JSON\n",
    "predictions_json_path = f'{OUTPUT_PATH}/predictions.json'\n",
    "with open(predictions_json_path, 'w') as f:\n",
    "    json.dump(all_predictions, f, indent=2)\n",
    "print(f\"‚úì JSON predictions saved: {predictions_json_path}\")\n",
    "\n",
    "# 2. Save as CSV\n",
    "if all_predictions:\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    predictions_csv_path = f'{OUTPUT_PATH}/predictions.csv'\n",
    "    df.to_csv(predictions_csv_path, index=False)\n",
    "    print(f\"‚úì CSV predictions saved: {predictions_csv_path}\")\n",
    "\n",
    "# 3. Save statistics\n",
    "stats_path = f'{OUTPUT_PATH}/detection_statistics.json'\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(detection_stats, f, indent=2)\n",
    "print(f\"‚úì Statistics saved: {stats_path}\")\n",
    "\n",
    "# 4. Create submission format (YOLO format)\n",
    "print(\"\\nCreating YOLO format labels...\")\n",
    "for pred in all_predictions:\n",
    "    img_name = pred['image']\n",
    "    label_path = f\"{OUTPUT_PATH}/labels/{img_name}.txt\"\n",
    "    \n",
    "    # Read image to get dimensions\n",
    "    img_path = test_path / f\"{img_name}.jpg\"\n",
    "    if not img_path.exists():\n",
    "        img_path = test_path / f\"{img_name}.png\"\n",
    "    \n",
    "    if img_path.exists():\n",
    "        img = cv2.imread(str(img_path))\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Convert to YOLO format (normalized)\n",
    "        x1, y1, x2, y2 = pred['bbox']\n",
    "        x_center = ((x1 + x2) / 2) / w\n",
    "        y_center = ((y1 + y2) / 2) / h\n",
    "        width = (x2 - x1) / w\n",
    "        height = (y2 - y1) / h\n",
    "        \n",
    "        # Append to label file\n",
    "        with open(label_path, 'a') as f:\n",
    "            f.write(f\"{pred['class_id']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f} {pred['confidence']:.6f}\\n\")\n",
    "\n",
    "print(f\"‚úì YOLO format labels saved: {OUTPUT_PATH}/labels/\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GENERATING SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "INFERENCE SUMMARY REPORT\n",
    "{'=' * 60}\n",
    "\n",
    "Timestamp: {datetime.now().isoformat()}\n",
    "Model: {MODEL_PATH}\n",
    "Test Images: {TEST_IMAGES_PATH}\n",
    "\n",
    "Configuration:\n",
    "  - Image Size: {CONFIG['imgsz']}\n",
    "  - Confidence Threshold: {CONFIG['conf_thres']}\n",
    "  - IOU Threshold: {CONFIG['iou_thres']}\n",
    "  - Max Detections: {CONFIG['max_det']}\n",
    "\n",
    "Results:\n",
    "  - Total Images: {detection_stats['total_images']}\n",
    "  - Images with Detections: {detection_stats['images_with_detections']}\n",
    "  - Total Detections: {detection_stats['total_detections']}\n",
    "  - Average Detections per Image: {detection_stats['total_detections'] / detection_stats['total_images']:.2f}\n",
    "\n",
    "Detections per Class:\n",
    "\"\"\"\n",
    "\n",
    "for class_name, count in sorted(detection_stats['detections_per_class'].items(), \n",
    "                                key=lambda x: x[1], reverse=True):\n",
    "    if count > 0:\n",
    "        percentage = (count / detection_stats['total_detections']) * 100\n",
    "        summary_report += f\"  - {class_name}: {count} ({percentage:.1f}%)\\n\"\n",
    "\n",
    "summary_report += f\"\\n{'=' * 60}\\n\"\n",
    "\n",
    "# Save summary report\n",
    "summary_path = f'{OUTPUT_PATH}/inference_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(summary_report)\n",
    "print(f\"‚úì Summary report saved: {summary_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INFERENCE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Output Directory: {OUTPUT_PATH}\")\n",
    "print(f\"\\nGenerated Files:\")\n",
    "print(f\"  ‚úì predictions.json - All predictions in JSON format\")\n",
    "print(f\"  ‚úì predictions.csv - All predictions in CSV format\")\n",
    "print(f\"  ‚úì labels/ - YOLO format label files\")\n",
    "print(f\"  ‚úì detection_statistics.json - Detection statistics\")\n",
    "print(f\"  ‚úì inference_summary.txt - Summary report\")\n",
    "if CONFIG['visualize']:\n",
    "    print(f\"  ‚úì visualizations/ - Annotated images\")\n",
    "print(f\"\\nüìä Detection Summary:\")\n",
    "print(f\"  Total Detections: {detection_stats['total_detections']}\")\n",
    "print(f\"  Images with Detections: {detection_stats['images_with_detections']}/{detection_stats['total_images']}\")\n",
    "print(f\"  Detection Rate: {(detection_stats['images_with_detections']/detection_stats['total_images']*100):.1f}%\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n‚úÖ All predictions have been generated successfully!\")\n",
    "print(\"Next step: Run create_submission.py to create the final ZIP file\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a8e1d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8819cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:35:50.417713Z",
     "iopub.status.busy": "2025-12-16T17:35:50.417338Z",
     "iopub.status.idle": "2025-12-16T17:36:10.952918Z",
     "shell.execute_reply": "2025-12-16T17:36:10.952199Z",
     "shell.execute_reply.started": "2025-12-16T17:35:50.417690Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Submission Package\n",
    "Compresses all code, results, and documentation into a ZIP file\n",
    "Compatible with train.py, validation.py, and inference.py workflow\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "WORKING_DIR = '/kaggle/working'\n",
    "OUTPUT_ZIP = f'{WORKING_DIR}/submission_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Files and directories to include\n",
    "INCLUDE_ITEMS = {\n",
    "    'code': [\n",
    "        'train.py',\n",
    "        'validation.py',\n",
    "        'inference.py',\n",
    "        'create_submission.py',\n",
    "        'corrected_data.yaml'\n",
    "    ],\n",
    "    'results': [\n",
    "        'training_summary.json',\n",
    "        'train/weights/best.pt',\n",
    "        'train/weights/last.pt',\n",
    "        'train/results.csv',\n",
    "        'train/results.png',\n",
    "        'train/confusion_matrix.png',\n",
    "        'train/confusion_matrix_normalized.png',\n",
    "        'validation_results/validation_results.json',\n",
    "        'validation_results/validation_summary.txt',\n",
    "        'inference_results/predictions.json',\n",
    "        'inference_results/predictions.csv',\n",
    "        'inference_results/detection_statistics.json',\n",
    "        'inference_results/inference_summary.txt',\n",
    "        'inference_results/labels/'  # Directory\n",
    "    ],\n",
    "    'visualizations': [\n",
    "        'train/val_batch0_pred.jpg',\n",
    "        'train/val_batch1_pred.jpg',\n",
    "        'train/val_batch2_pred.jpg',\n",
    "        'inference_results/visualizations/'  # Directory (optional)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def get_dir_size(path):\n",
    "    \"\"\"Calculate directory size in MB\"\"\"\n",
    "    total = 0\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return total / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "def add_to_zip(zipf, source_path, archive_name):\n",
    "    \"\"\"Add file or directory to zip\"\"\"\n",
    "    source = Path(source_path)\n",
    "    \n",
    "    if not source.exists():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        if source.is_file():\n",
    "            zipf.write(source, archive_name)\n",
    "            return True\n",
    "        elif source.is_dir():\n",
    "            # Add directory and its contents\n",
    "            for root, dirs, files in os.walk(source):\n",
    "                for file in files:\n",
    "                    file_path = Path(root) / file\n",
    "                    archive_path = Path(archive_name) / file_path.relative_to(source)\n",
    "                    zipf.write(file_path, archive_path)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Warning: Could not add {source_path}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE README\n",
    "# ============================================================================\n",
    "\n",
    "def create_readme():\n",
    "    \"\"\"Create README file for submission\"\"\"\n",
    "    readme_content = f\"\"\"\n",
    "# Military Object Detection - Submission Package\n",
    "\n",
    "## Overview\n",
    "This package contains the complete code, trained models, and results for the military object detection project using YOLOv8.\n",
    "\n",
    "**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Contents\n",
    "\n",
    "### üìÑ Code Files\n",
    "- `train.py` - Main training script with YOLOv8\n",
    "- `validation.py` - Comprehensive validation script\n",
    "- `inference.py` - Inference script for test set predictions\n",
    "- `create_submission.py` - This packaging script\n",
    "- `corrected_data.yaml` - Dataset configuration\n",
    "\n",
    "### üéØ Trained Models\n",
    "- `train/weights/best.pt` - Best model based on validation mAP\n",
    "- `train/weights/last.pt` - Last epoch checkpoint\n",
    "\n",
    "### üìä Results\n",
    "- `training_summary.json` - Training metrics and configuration\n",
    "- `train/results.csv` - Epoch-by-epoch training metrics\n",
    "- `train/results.png` - Training curves visualization\n",
    "- `train/confusion_matrix.png` - Confusion matrix (unnormalized)\n",
    "- `train/confusion_matrix_normalized.png` - Normalized confusion matrix\n",
    "\n",
    "### ‚úÖ Validation Results\n",
    "- `validation_results/validation_results.json` - Detailed validation metrics\n",
    "- `validation_results/validation_summary.txt` - Human-readable summary\n",
    "- Per-class performance metrics\n",
    "\n",
    "### üîç Inference Results\n",
    "- `inference_results/predictions.json` - All predictions in JSON format\n",
    "- `inference_results/predictions.csv` - All predictions in CSV format\n",
    "- `inference_results/labels/` - YOLO format label files\n",
    "- `inference_results/detection_statistics.json` - Detection statistics\n",
    "- `inference_results/inference_summary.txt` - Inference summary\n",
    "- `inference_results/visualizations/` - Annotated test images (if included)\n",
    "\n",
    "### üìà Visualizations\n",
    "- Sample validation batch predictions\n",
    "- Training and validation curves\n",
    "- Confusion matrices\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "Please refer to:\n",
    "- `training_summary.json` for overall training metrics\n",
    "- `validation_results/validation_summary.txt` for detailed validation performance\n",
    "- `inference_results/inference_summary.txt` for test set statistics\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Training\n",
    "```bash\n",
    "python train.py\n",
    "```\n",
    "\n",
    "### Validation\n",
    "```bash\n",
    "python validation.py\n",
    "```\n",
    "\n",
    "### Inference\n",
    "```bash\n",
    "python inference.py\n",
    "```\n",
    "\n",
    "### Create Submission Package\n",
    "```bash\n",
    "python create_submission.py\n",
    "```\n",
    "\n",
    "## Requirements\n",
    "- Python 3.8+\n",
    "- PyTorch\n",
    "- Ultralytics YOLOv8\n",
    "- OpenCV\n",
    "- NumPy\n",
    "- Pandas\n",
    "- PyYAML\n",
    "\n",
    "## Model Architecture\n",
    "- **Base Model:** YOLOv8m (Medium)\n",
    "- **Input Size:** 640x640\n",
    "- **Classes:** 12 military object categories\n",
    "\n",
    "## Notes\n",
    "- All paths in scripts are configured for Kaggle environment\n",
    "- Adjust paths if running in different environment\n",
    "- Models are trained with strong data augmentation\n",
    "- Early stopping enabled to prevent overfitting\n",
    "\n",
    "## Contact\n",
    "Centre of Excellence - AI Lab\n",
    "Department of Computer Science & Engineering\n",
    "\n",
    "---\n",
    "*Generated automatically by create_submission.py*\n",
    "\"\"\"\n",
    "    \n",
    "    readme_path = f'{WORKING_DIR}/README.md'\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    return readme_path\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING SUBMISSION PACKAGE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Working directory: {WORKING_DIR}\")\n",
    "print(f\"Output ZIP: {OUTPUT_ZIP}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Change to working directory\n",
    "os.chdir(WORKING_DIR)\n",
    "\n",
    "# Create README\n",
    "print(\"\\nüìù Creating README...\")\n",
    "readme_path = create_readme()\n",
    "print(f\"‚úì README created: {readme_path}\")\n",
    "\n",
    "# Create manifest\n",
    "manifest = {\n",
    "    'created': datetime.now().isoformat(),\n",
    "    'description': 'Military Object Detection Submission Package',\n",
    "    'included_files': {},\n",
    "    'statistics': {}\n",
    "}\n",
    "\n",
    "# Create ZIP file\n",
    "print(f\"\\nüì¶ Creating ZIP file: {OUTPUT_ZIP}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "included_count = 0\n",
    "skipped_count = 0\n",
    "total_size = 0\n",
    "\n",
    "with zipfile.ZipFile(OUTPUT_ZIP, 'w', zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n",
    "    \n",
    "    # Add README first\n",
    "    print(\"\\nüìÑ Adding README...\")\n",
    "    zipf.write(readme_path, 'README.md')\n",
    "    included_count += 1\n",
    "    \n",
    "    # Process code files\n",
    "    print(\"\\nüíª Adding Code Files:\")\n",
    "    code_added = []\n",
    "    for item in INCLUDE_ITEMS['code']:\n",
    "        if Path(item).exists():\n",
    "            if add_to_zip(zipf, item, f'code/{item}'):\n",
    "                print(f\"  ‚úì {item}\")\n",
    "                code_added.append(item)\n",
    "                included_count += 1\n",
    "            else:\n",
    "                print(f\"  ‚úó {item} (failed)\")\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            print(f\"  ‚äó {item} (not found)\")\n",
    "            skipped_count += 1\n",
    "    \n",
    "    manifest['included_files']['code'] = code_added\n",
    "    \n",
    "    # Process results\n",
    "    print(\"\\nüìä Adding Results:\")\n",
    "    results_added = []\n",
    "    for item in INCLUDE_ITEMS['results']:\n",
    "        if Path(item).exists():\n",
    "            if add_to_zip(zipf, item, f'results/{Path(item).name}'):\n",
    "                size = Path(item).stat().st_size if Path(item).is_file() else get_dir_size(item)\n",
    "                print(f\"  ‚úì {item} ({size/1e6:.2f} MB)\")\n",
    "                results_added.append(item)\n",
    "                included_count += 1\n",
    "                total_size += size\n",
    "            else:\n",
    "                print(f\"  ‚úó {item} (failed)\")\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            print(f\"  ‚äó {item} (not found)\")\n",
    "            skipped_count += 1\n",
    "    \n",
    "    manifest['included_files']['results'] = results_added\n",
    "    \n",
    "    # Process visualizations (optional)\n",
    "    print(\"\\nüñºÔ∏è  Adding Visualizations:\")\n",
    "    viz_added = []\n",
    "    for item in INCLUDE_ITEMS['visualizations']:\n",
    "        if Path(item).exists():\n",
    "            if add_to_zip(zipf, item, f'visualizations/{Path(item).name}'):\n",
    "                print(f\"  ‚úì {item}\")\n",
    "                viz_added.append(item)\n",
    "                included_count += 1\n",
    "            else:\n",
    "                print(f\"  ‚úó {item} (failed)\")\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            print(f\"  ‚äó {item} (optional, not found)\")\n",
    "    \n",
    "    manifest['included_files']['visualizations'] = viz_added\n",
    "    \n",
    "    # Add manifest\n",
    "    manifest['statistics'] = {\n",
    "        'files_included': included_count,\n",
    "        'files_skipped': skipped_count,\n",
    "        'total_size_mb': total_size / 1e6\n",
    "    }\n",
    "    \n",
    "    manifest_path = 'manifest.json'\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    zipf.write(manifest_path, 'manifest.json')\n",
    "    print(f\"\\nüìã Manifest added: manifest.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Get final ZIP size\n",
    "zip_size = Path(OUTPUT_ZIP).stat().st_size / (1024 * 1024)  # MB\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUBMISSION PACKAGE CREATED SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüì¶ Package Details:\")\n",
    "print(f\"  Location: {OUTPUT_ZIP}\")\n",
    "print(f\"  Size: {zip_size:.2f} MB\")\n",
    "print(f\"  Files included: {included_count}\")\n",
    "print(f\"  Files skipped: {skipped_count}\")\n",
    "\n",
    "print(f\"\\nüìÇ Package Contents:\")\n",
    "print(f\"  ‚úì README.md - Complete documentation\")\n",
    "print(f\"  ‚úì manifest.json - File listing and metadata\")\n",
    "print(f\"  ‚úì code/ - All Python scripts and configuration\")\n",
    "print(f\"  ‚úì results/ - Training, validation, and inference results\")\n",
    "print(f\"  ‚úì visualizations/ - Sample predictions and plots\")\n",
    "\n",
    "print(f\"\\nüíæ Storage:\")\n",
    "print(f\"  Compressed: {zip_size:.2f} MB\")\n",
    "print(f\"  Original: {total_size/1e6:.2f} MB\")\n",
    "print(f\"  Compression ratio: {(1 - zip_size/(total_size/1e6))*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Package ready for submission!\")\n",
    "print(f\"üì• Download: {OUTPUT_ZIP}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Print warning if model files are missing\n",
    "if not Path('train/weights/best.pt').exists():\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Best model weights not found!\")\n",
    "    print(\"   Make sure training completed successfully before creating submission.\")\n",
    "\n",
    "if skipped_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Note: {skipped_count} files were skipped (not found or failed to add)\")\n",
    "    print(\"   This is normal if you haven't run all scripts yet.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8d1b5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8985153,
     "sourceId": 14106832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.040917,
   "end_time": "2025-12-16T17:49:46.135826",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-16T17:49:37.094909",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
